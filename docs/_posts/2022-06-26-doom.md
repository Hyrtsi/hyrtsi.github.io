---
layout: post
title:  "Playing FPS games using Reinforcement Learning"
date:   2022-06-26 13:37:00 +0200
---

## Playing FPS games using Reinforcement Learning

I like programming, math, machine learning and video games. Apparently reinforcement learning combines all of these. This is a series of posts of my journey in coming up with some kickass machine learning algorithms.

![Doom2]({{site.baseurl}}/assets/doom2.jpg)


Computers have been invented to mimic human behavior and automate tasks for us. The AI research has been around since the 1950s but it skyrocketed in the 2010s because the availability of data and powerful hardware. You can see some of the major milestones in machine learning [here](https://en.wikipedia.org/wiki/Timeline_of_machine_learning) and AI [here](https://en.wikipedia.org/wiki/Timeline_of_artificial_intelligence) if you want some perspective.

[Reinforcement learning](https://www.amazon.com/Reinforcement-Learning-Introduction-Adaptive-Computation/dp/0262039249/ref=dp_ob_title_bk) is one of the three basic machine learning paradigms alongside with supervised learning and unsupervised learning. The agents take actions and get rewards for their actions. This kind of learning resembles video games or how we teach our dogs to fetch us things.

[This](https://arxiv.org/abs/1312.5602) paper was an important one in reinforcement learning. The model learns to play Atari games such as pong from raw pixel data. We fast forward a few years and we get [AlphaGo](https://www.deepmind.com/research/highlighted-research/alphago): an AI that plays the ancient game of go at superhuman level and beats the world champion in the game. Just a few years after that, [AlphaZero](https://www.deepmind.com/blog/alphazero-shedding-new-light-on-chess-shogi-and-go): AI that plays not only go but also other board games at super-human level without any human training data by just playing against itself. Finally, in 2020, we get [MuZero](https://www.deepmind.com/blog/muzero-mastering-go-chess-shogi-and-atari-without-rules) that beats all the other algorithms in go, chess, shogi, atari and other games without knowing the rules of the game beforehand.

I heard just recently of [PPO](https://openai.com/blog/openai-baselines-ppo/) and [PPG](https://arxiv.org/abs/2009.04416) and I think I could continue this forever. We have to celebrate our amazing AI research that is definitely going towards a general AI that

- doesn't need to know the rules of the game beforehand
- does not need human-generated data to learn but learns from trial and error
- handles the huge dimensionality of the state space
- can play several games using raw sensory data instead of highly pre-processed data
- comes up with creative solutions to problems
- requires 
- surpasses human players

However, Atari games, chess, shogi and go contain no hidden information. All the players in the game see the full state at one glance. The amount of legal states in a go board is $3^{361}$ or $10^{170}$ if that makes any more sense.


